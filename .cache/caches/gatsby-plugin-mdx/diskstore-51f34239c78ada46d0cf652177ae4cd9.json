{"expireTime":9007200870193041000,"key":"gatsby-plugin-mdx-entire-payload-8fa93cf4105fb1f1c27d3d3352ba2b26-","val":{"mdast":{"type":"root","children":[{"type":"paragraph","children":[{"type":"text","value":"A core abstraction behind popular neural networks is a computational graph, a directed graph with its nodes corresponding to operations (ops) and input variables. One node's output value is the input to another node. The WebNN API brings this abstraction to the web.","position":{"start":{"line":2,"column":1,"offset":1},"end":{"line":2,"column":267,"offset":267},"indent":[]}}],"position":{"start":{"line":2,"column":1,"offset":1},"end":{"line":2,"column":267,"offset":267},"indent":[]}},{"type":"paragraph","children":[{"type":"text","value":"In the WebNN API, the ","position":{"start":{"line":4,"column":1,"offset":269},"end":{"line":4,"column":23,"offset":291},"indent":[]}},{"type":"link","title":null,"url":"https://webmachinelearning.github.io/webnn/#operand","children":[{"type":"inlineCode","value":"Operand","position":{"start":{"line":4,"column":24,"offset":292},"end":{"line":4,"column":33,"offset":301},"indent":[]}}],"position":{"start":{"line":4,"column":23,"offset":291},"end":{"line":4,"column":87,"offset":355},"indent":[]}},{"type":"text","value":" objects represent input, output, and constant multi-dimensional arrays known as ","position":{"start":{"line":4,"column":87,"offset":355},"end":{"line":4,"column":168,"offset":436},"indent":[]}},{"type":"link","title":null,"url":"https://mathworld.wolfram.com/Tensor.html","children":[{"type":"text","value":"tensors","position":{"start":{"line":4,"column":169,"offset":437},"end":{"line":4,"column":176,"offset":444},"indent":[]}}],"position":{"start":{"line":4,"column":168,"offset":436},"end":{"line":4,"column":220,"offset":488},"indent":[]}},{"type":"text","value":". The ","position":{"start":{"line":4,"column":220,"offset":488},"end":{"line":4,"column":226,"offset":494},"indent":[]}},{"type":"link","title":null,"url":"https://webmachinelearning.github.io/webnn/#api-neuralnetworkcontext","children":[{"type":"inlineCode","value":"NeuralNetworkContext","position":{"start":{"line":4,"column":227,"offset":495},"end":{"line":4,"column":249,"offset":517},"indent":[]}}],"position":{"start":{"line":4,"column":226,"offset":494},"end":{"line":4,"column":320,"offset":588},"indent":[]}},{"type":"text","value":" defines a set of operations that facilitate the construction and execution of this computational graph. Such operations may be accelerated with dedicated hardware such as the GPUs, CPUs with extensions for deep learning, or dedicated ML accelerators. These operations defined by the WebNN API are required by ","position":{"start":{"line":4,"column":320,"offset":588},"end":{"line":4,"column":630,"offset":898},"indent":[]}},{"type":"link","title":null,"url":"https://github.com/webmachinelearning/webnn/blob/master/op_compatibility/first_wave_models.md","children":[{"type":"text","value":"models","position":{"start":{"line":4,"column":631,"offset":899},"end":{"line":4,"column":637,"offset":905},"indent":[]}}],"position":{"start":{"line":4,"column":630,"offset":898},"end":{"line":4,"column":733,"offset":1001},"indent":[]}},{"type":"text","value":" that address key application use cases. Additionally, the WebNN API provides affordances to builder a computational graph, compile the graph, execute the graph, and integrate the graph with other Web APIs that provide input data to the graph e.g. media APIs for image or video frames and sensor APIs for sensory data.","position":{"start":{"line":4,"column":733,"offset":1001},"end":{"line":4,"column":1051,"offset":1319},"indent":[]}}],"position":{"start":{"line":4,"column":1,"offset":269},"end":{"line":4,"column":1051,"offset":1319},"indent":[]}},{"type":"paragraph","children":[{"type":"text","value":"This ","position":{"start":{"line":6,"column":1,"offset":1321},"end":{"line":6,"column":6,"offset":1326},"indent":[]}},{"type":"link","title":null,"url":"https://webmachinelearning.github.io/webnn/#examples","children":[{"type":"text","value":"example","position":{"start":{"line":6,"column":7,"offset":1327},"end":{"line":6,"column":14,"offset":1334},"indent":[]}}],"position":{"start":{"line":6,"column":6,"offset":1326},"end":{"line":6,"column":69,"offset":1389},"indent":[]}},{"type":"text","value":" builds, compiles, and executes a graph comprised of three ops, takes four inputs and returns one output.","position":{"start":{"line":6,"column":69,"offset":1389},"end":{"line":6,"column":174,"offset":1494},"indent":[]}}],"position":{"start":{"line":6,"column":1,"offset":1321},"end":{"line":6,"column":174,"offset":1494},"indent":[]}},{"type":"heading","depth":2,"children":[{"type":"text","value":"Key scenarios","position":{"start":{"line":8,"column":4,"offset":1499},"end":{"line":8,"column":17,"offset":1512},"indent":[]}}],"position":{"start":{"line":8,"column":1,"offset":1496},"end":{"line":8,"column":17,"offset":1512},"indent":[]}},{"type":"paragraph","children":[{"type":"text","value":"There are many important ","position":{"start":{"line":10,"column":1,"offset":1514},"end":{"line":10,"column":26,"offset":1539},"indent":[]}},{"type":"link","title":null,"url":"https://webmachinelearning.github.io/webnn/#usecases-application","children":[{"type":"text","value":"application use cases","position":{"start":{"line":10,"column":27,"offset":1540},"end":{"line":10,"column":48,"offset":1561},"indent":[]}}],"position":{"start":{"line":10,"column":26,"offset":1539},"end":{"line":10,"column":115,"offset":1628},"indent":[]}},{"type":"text","value":" for high-performance neural network inference. One such use case is deep-learning noise suppression (DNS) in web-based video conferencing. The following sample shows how the ","position":{"start":{"line":10,"column":115,"offset":1628},"end":{"line":10,"column":290,"offset":1803},"indent":[]}},{"type":"link","title":null,"url":"https://github.com/microsoft/DNS-Challenge/tree/master/NSNet2-baseline","children":[{"type":"text","value":"NSNet2","position":{"start":{"line":10,"column":291,"offset":1804},"end":{"line":10,"column":297,"offset":1810},"indent":[]}}],"position":{"start":{"line":10,"column":290,"offset":1803},"end":{"line":10,"column":370,"offset":1883},"indent":[]}},{"type":"text","value":" baseline implementation of deep learning-based noise suppression model may be implemented using the WebNN API.","position":{"start":{"line":10,"column":370,"offset":1883},"end":{"line":10,"column":481,"offset":1994},"indent":[]}}],"position":{"start":{"line":10,"column":1,"offset":1514},"end":{"line":10,"column":481,"offset":1994},"indent":[]}},{"type":"code","lang":"JavaScript","meta":null,"value":"// Noise Suppression Net 2 (NSNet2) Baseline Model for Deep Noise Suppression Challenge (DNS) 2021.\nexport class NSNet2 {\n  constructor() {\n    this.model = null;\n    this.compiledModel = null;\n    this.frameSize = 161;\n    this.hiddenSize = 400;\n  }\n\n  async load(baseUrl, batchSize, frames) {\n    const nn = navigator.ml.getNeuralNetworkContext();\n    const builder = nn.createModelBuilder();\n    // Create constants by loading pre-trained data from .npy files.\n    const weight172 = await buildConstantByNpy(builder, baseUrl + '172.npy');\n    const biasFcIn0 = await buildConstantByNpy(builder, baseUrl + 'fc_in_0_bias.npy');\n    const weight192 = await buildConstantByNpy(builder, baseUrl + '192.npy');\n    const recurrentWeight193 = await buildConstantByNpy(builder, baseUrl + '193.npy');\n    const bias194 = await buildConstantByNpy(builder, baseUrl + '194_0.npy');\n    const recurrentBias194 = await buildConstantByNpy(builder, baseUrl + '194_1.npy');\n    const weight212 = await buildConstantByNpy(builder, baseUrl + '212.npy');\n    const recurrentWeight213 = await buildConstantByNpy(builder, baseUrl + '213.npy');\n    const bias214 = await buildConstantByNpy(builder, baseUrl + '214_0.npy');\n    const recurrentBias214 = await buildConstantByNpy(builder, baseUrl + '214_1.npy');\n    const weight215 = await buildConstantByNpy(builder, baseUrl + '215.npy');\n    const biasFcOut0 = await buildConstantByNpy(builder, baseUrl + 'fc_out_0_bias.npy');\n    const weight216 = await buildConstantByNpy(builder, baseUrl + '216.npy');\n    const biasFcOut2 = await buildConstantByNpy(builder, baseUrl + 'fc_out_2_bias.npy');\n    const weight217 = await buildConstantByNpy(builder, baseUrl + '217.npy');\n    const biasFcOut4 = await buildConstantByNpy(builder, baseUrl + 'fc_out_4_bias.npy');\n    // Build up the network.\n    const input = builder.input('input', {type: 'float32', dimensions: [batchSize, frames, this.frameSize]});\n    const relu20 = builder.relu(builder.add(builder.matmul(input, weight172), biasFcIn0));\n    const transpose31 = builder.transpose(relu20, {permutation: [1, 0, 2]});\n    const initialState92 = builder.input('initialState92', {type: 'float32', dimensions: [1, batchSize, this.hiddenSize]});\n    const [gru94, gru93] = builder.gru(transpose31, weight192, recurrentWeight193, frames, this.hiddenSize,\n        {bias: bias194, recurrentBias: recurrentBias194, initialHiddenState: initialState92, returnSequence: true});\n    const squeeze95 = builder.squeeze(gru93, {axes: [1]});\n    const initialState155 = builder.input('initialState155', {type: 'float32', dimensions: [1, batchSize, this.hiddenSize]});\n    const [gru157, gru156] = builder.gru(squeeze95, weight212, recurrentWeight213, frames, this.hiddenSize,\n        {bias: bias214, recurrentBias: recurrentBias214, initialHiddenState: initialState155, returnSequence: true});\n    const squeeze158 = builder.squeeze(gru156, {axes: [1]});\n    const transpose159 = builder.transpose(squeeze158, {permutation: [1, 0, 2]});\n    const relu163 = builder.relu(builder.add(builder.matmul(transpose159, weight215), biasFcOut0));\n    const relu167 = builder.relu(builder.add(builder.matmul(relu163, weight216), biasFcOut2));\n    const output = builder.sigmoid(builder.add(builder.matmul(relu167, weight217), biasFcOut4));\n    this.model = builder.createModel({output, gru94, gru157});\n  }\n\n  async compile(options) {\n    this.compiledModel = await this.model.compile(options);\n  }\n\n  async compute(inputBuffer, initialState92Buffer, initialState155Buffer) {\n    const inputs = {\n      input: {buffer: inputBuffer},\n      initialState92: {buffer: initialState92Buffer},\n      initialState155: {buffer: initialState155Buffer},\n    };\n    return await this.compiledModel.compute(inputs);\n  }\n}","position":{"start":{"line":12,"column":1,"offset":1996},"end":{"line":74,"column":4,"offset":5774},"indent":[1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1]}},{"type":"paragraph","children":[{"type":"text","value":"Try the live version of the ","position":{"start":{"line":76,"column":1,"offset":5776},"end":{"line":76,"column":29,"offset":5804},"indent":[]}},{"type":"link","title":null,"url":"https://webmachinelearning.github.io/webnn-samples/nsnet2/","children":[{"type":"text","value":"WebNN NSNet2 example","position":{"start":{"line":76,"column":30,"offset":5805},"end":{"line":76,"column":50,"offset":5825},"indent":[]}}],"position":{"start":{"line":76,"column":29,"offset":5804},"end":{"line":76,"column":111,"offset":5886},"indent":[]}},{"type":"text","value":".  This live version builds upon ","position":{"start":{"line":76,"column":111,"offset":5886},"end":{"line":76,"column":144,"offset":5919},"indent":[]}},{"type":"link","title":null,"url":"https://github.com/webmachinelearning/webnn-samples/blob/master/nsnet2/nsnet2.js","children":[{"type":"text","value":"nsnet2.js","position":{"start":{"line":76,"column":145,"offset":5920},"end":{"line":76,"column":154,"offset":5929},"indent":[]}}],"position":{"start":{"line":76,"column":144,"offset":5919},"end":{"line":76,"column":237,"offset":6012},"indent":[]}},{"type":"text","value":" that implements the above code snippet as a JS module.","position":{"start":{"line":76,"column":237,"offset":6012},"end":{"line":76,"column":292,"offset":6067},"indent":[]}}],"position":{"start":{"line":76,"column":1,"offset":5776},"end":{"line":76,"column":292,"offset":6067},"indent":[]}},{"type":"export","value":"export const _frontmatter = {\"title\":\"Get Started\",\"author\":\"Anssi, Chai and Ningxin\",\"avatar\":\"https://avatars.githubusercontent.com/u/379216?s=200&v=4\",\"date\":\"2020-05-02T23:46:37.121Z\"}","position":{"start":{"line":78,"column":1,"offset":6069},"end":{"line":78,"column":189,"offset":6257},"indent":[]}}],"position":{"start":{"line":1,"column":1,"offset":0},"end":{"line":78,"column":189,"offset":6257}}},"scopeImports":["import * as React from 'react'"],"scopeIdentifiers":["React"],"body":"function _extends() { _extends = Object.assign || function (target) { for (var i = 1; i < arguments.length; i++) { var source = arguments[i]; for (var key in source) { if (Object.prototype.hasOwnProperty.call(source, key)) { target[key] = source[key]; } } } return target; }; return _extends.apply(this, arguments); }\n\nfunction _objectWithoutProperties(source, excluded) { if (source == null) return {}; var target = _objectWithoutPropertiesLoose(source, excluded); var key, i; if (Object.getOwnPropertySymbols) { var sourceSymbolKeys = Object.getOwnPropertySymbols(source); for (i = 0; i < sourceSymbolKeys.length; i++) { key = sourceSymbolKeys[i]; if (excluded.indexOf(key) >= 0) continue; if (!Object.prototype.propertyIsEnumerable.call(source, key)) continue; target[key] = source[key]; } } return target; }\n\nfunction _objectWithoutPropertiesLoose(source, excluded) { if (source == null) return {}; var target = {}; var sourceKeys = Object.keys(source); var key, i; for (i = 0; i < sourceKeys.length; i++) { key = sourceKeys[i]; if (excluded.indexOf(key) >= 0) continue; target[key] = source[key]; } return target; }\n\n/* @jsxRuntime classic */\n\n/* @jsx mdx */\nvar _frontmatter = {\n  \"title\": \"Get Started\",\n  \"author\": \"Anssi, Chai and Ningxin\",\n  \"avatar\": \"https://avatars.githubusercontent.com/u/379216?s=200&v=4\",\n  \"date\": \"2020-05-02T23:46:37.121Z\"\n};\nvar layoutProps = {\n  _frontmatter: _frontmatter\n};\nvar MDXLayout = \"wrapper\";\nreturn function MDXContent(_ref) {\n  var components = _ref.components,\n      props = _objectWithoutProperties(_ref, [\"components\"]);\n\n  return mdx(MDXLayout, _extends({}, layoutProps, props, {\n    components: components,\n    mdxType: \"MDXLayout\"\n  }), mdx(\"p\", null, \"A core abstraction behind popular neural networks is a computational graph, a directed graph with its nodes corresponding to operations (ops) and input variables. One node\\u2019s output value is the input to another node. The WebNN API brings this abstraction to the web.\"), mdx(\"p\", null, \"In the WebNN API, the \", mdx(\"a\", {\n    parentName: \"p\",\n    \"href\": \"https://webmachinelearning.github.io/webnn/#operand\"\n  }, mdx(\"inlineCode\", {\n    parentName: \"a\"\n  }, \"Operand\")), \" objects represent input, output, and constant multi-dimensional arrays known as \", mdx(\"a\", {\n    parentName: \"p\",\n    \"href\": \"https://mathworld.wolfram.com/Tensor.html\"\n  }, \"tensors\"), \". The \", mdx(\"a\", {\n    parentName: \"p\",\n    \"href\": \"https://webmachinelearning.github.io/webnn/#api-neuralnetworkcontext\"\n  }, mdx(\"inlineCode\", {\n    parentName: \"a\"\n  }, \"NeuralNetworkContext\")), \" defines a set of operations that facilitate the construction and execution of this computational graph. Such operations may be accelerated with dedicated hardware such as the GPUs, CPUs with extensions for deep learning, or dedicated ML accelerators. These operations defined by the WebNN API are required by \", mdx(\"a\", {\n    parentName: \"p\",\n    \"href\": \"https://github.com/webmachinelearning/webnn/blob/master/op_compatibility/first_wave_models.md\"\n  }, \"models\"), \" that address key application use cases. Additionally, the WebNN API provides affordances to builder a computational graph, compile the graph, execute the graph, and integrate the graph with other Web APIs that provide input data to the graph e.g. media APIs for image or video frames and sensor APIs for sensory data.\"), mdx(\"p\", null, \"This \", mdx(\"a\", {\n    parentName: \"p\",\n    \"href\": \"https://webmachinelearning.github.io/webnn/#examples\"\n  }, \"example\"), \" builds, compiles, and executes a graph comprised of three ops, takes four inputs and returns one output.\"), mdx(\"h2\", null, \"Key scenarios\"), mdx(\"p\", null, \"There are many important \", mdx(\"a\", {\n    parentName: \"p\",\n    \"href\": \"https://webmachinelearning.github.io/webnn/#usecases-application\"\n  }, \"application use cases\"), \" for high-performance neural network inference. One such use case is deep-learning noise suppression (DNS) in web-based video conferencing. The following sample shows how the \", mdx(\"a\", {\n    parentName: \"p\",\n    \"href\": \"https://github.com/microsoft/DNS-Challenge/tree/master/NSNet2-baseline\"\n  }, \"NSNet2\"), \" baseline implementation of deep learning-based noise suppression model may be implemented using the WebNN API.\"), mdx(\"pre\", null, mdx(\"code\", {\n    parentName: \"pre\",\n    \"className\": \"language-JavaScript\"\n  }, \"// Noise Suppression Net 2 (NSNet2) Baseline Model for Deep Noise Suppression Challenge (DNS) 2021.\\nexport class NSNet2 {\\n  constructor() {\\n    this.model = null;\\n    this.compiledModel = null;\\n    this.frameSize = 161;\\n    this.hiddenSize = 400;\\n  }\\n\\n  async load(baseUrl, batchSize, frames) {\\n    const nn = navigator.ml.getNeuralNetworkContext();\\n    const builder = nn.createModelBuilder();\\n    // Create constants by loading pre-trained data from .npy files.\\n    const weight172 = await buildConstantByNpy(builder, baseUrl + '172.npy');\\n    const biasFcIn0 = await buildConstantByNpy(builder, baseUrl + 'fc_in_0_bias.npy');\\n    const weight192 = await buildConstantByNpy(builder, baseUrl + '192.npy');\\n    const recurrentWeight193 = await buildConstantByNpy(builder, baseUrl + '193.npy');\\n    const bias194 = await buildConstantByNpy(builder, baseUrl + '194_0.npy');\\n    const recurrentBias194 = await buildConstantByNpy(builder, baseUrl + '194_1.npy');\\n    const weight212 = await buildConstantByNpy(builder, baseUrl + '212.npy');\\n    const recurrentWeight213 = await buildConstantByNpy(builder, baseUrl + '213.npy');\\n    const bias214 = await buildConstantByNpy(builder, baseUrl + '214_0.npy');\\n    const recurrentBias214 = await buildConstantByNpy(builder, baseUrl + '214_1.npy');\\n    const weight215 = await buildConstantByNpy(builder, baseUrl + '215.npy');\\n    const biasFcOut0 = await buildConstantByNpy(builder, baseUrl + 'fc_out_0_bias.npy');\\n    const weight216 = await buildConstantByNpy(builder, baseUrl + '216.npy');\\n    const biasFcOut2 = await buildConstantByNpy(builder, baseUrl + 'fc_out_2_bias.npy');\\n    const weight217 = await buildConstantByNpy(builder, baseUrl + '217.npy');\\n    const biasFcOut4 = await buildConstantByNpy(builder, baseUrl + 'fc_out_4_bias.npy');\\n    // Build up the network.\\n    const input = builder.input('input', {type: 'float32', dimensions: [batchSize, frames, this.frameSize]});\\n    const relu20 = builder.relu(builder.add(builder.matmul(input, weight172), biasFcIn0));\\n    const transpose31 = builder.transpose(relu20, {permutation: [1, 0, 2]});\\n    const initialState92 = builder.input('initialState92', {type: 'float32', dimensions: [1, batchSize, this.hiddenSize]});\\n    const [gru94, gru93] = builder.gru(transpose31, weight192, recurrentWeight193, frames, this.hiddenSize,\\n        {bias: bias194, recurrentBias: recurrentBias194, initialHiddenState: initialState92, returnSequence: true});\\n    const squeeze95 = builder.squeeze(gru93, {axes: [1]});\\n    const initialState155 = builder.input('initialState155', {type: 'float32', dimensions: [1, batchSize, this.hiddenSize]});\\n    const [gru157, gru156] = builder.gru(squeeze95, weight212, recurrentWeight213, frames, this.hiddenSize,\\n        {bias: bias214, recurrentBias: recurrentBias214, initialHiddenState: initialState155, returnSequence: true});\\n    const squeeze158 = builder.squeeze(gru156, {axes: [1]});\\n    const transpose159 = builder.transpose(squeeze158, {permutation: [1, 0, 2]});\\n    const relu163 = builder.relu(builder.add(builder.matmul(transpose159, weight215), biasFcOut0));\\n    const relu167 = builder.relu(builder.add(builder.matmul(relu163, weight216), biasFcOut2));\\n    const output = builder.sigmoid(builder.add(builder.matmul(relu167, weight217), biasFcOut4));\\n    this.model = builder.createModel({output, gru94, gru157});\\n  }\\n\\n  async compile(options) {\\n    this.compiledModel = await this.model.compile(options);\\n  }\\n\\n  async compute(inputBuffer, initialState92Buffer, initialState155Buffer) {\\n    const inputs = {\\n      input: {buffer: inputBuffer},\\n      initialState92: {buffer: initialState92Buffer},\\n      initialState155: {buffer: initialState155Buffer},\\n    };\\n    return await this.compiledModel.compute(inputs);\\n  }\\n}\\n\")), mdx(\"p\", null, \"Try the live version of the \", mdx(\"a\", {\n    parentName: \"p\",\n    \"href\": \"https://webmachinelearning.github.io/webnn-samples/nsnet2/\"\n  }, \"WebNN NSNet2 example\"), \".  This live version builds upon \", mdx(\"a\", {\n    parentName: \"p\",\n    \"href\": \"https://github.com/webmachinelearning/webnn-samples/blob/master/nsnet2/nsnet2.js\"\n  }, \"nsnet2.js\"), \" that implements the above code snippet as a JS module.\"));\n}\n;\nMDXContent.isMDXComponent = true;","rawMDXOutput":"/* @jsx mdx */\nimport { mdx } from '@mdx-js/react';\n/* @jsxRuntime classic */\n/* @jsx mdx */\n\nexport const _frontmatter = {\n  \"title\": \"Get Started\",\n  \"author\": \"Anssi, Chai and Ningxin\",\n  \"avatar\": \"https://avatars.githubusercontent.com/u/379216?s=200&v=4\",\n  \"date\": \"2020-05-02T23:46:37.121Z\"\n};\n\nconst layoutProps = {\n  _frontmatter\n};\nconst MDXLayout = \"wrapper\"\nexport default function MDXContent({\n  components,\n  ...props\n}) {\n  return <MDXLayout {...layoutProps} {...props} components={components} mdxType=\"MDXLayout\">\n    <p>{`A core abstraction behind popular neural networks is a computational graph, a directed graph with its nodes corresponding to operations (ops) and input variables. One node’s output value is the input to another node. The WebNN API brings this abstraction to the web.`}</p>\n    <p>{`In the WebNN API, the `}<a parentName=\"p\" {...{\n        \"href\": \"https://webmachinelearning.github.io/webnn/#operand\"\n      }}><inlineCode parentName=\"a\">{`Operand`}</inlineCode></a>{` objects represent input, output, and constant multi-dimensional arrays known as `}<a parentName=\"p\" {...{\n        \"href\": \"https://mathworld.wolfram.com/Tensor.html\"\n      }}>{`tensors`}</a>{`. The `}<a parentName=\"p\" {...{\n        \"href\": \"https://webmachinelearning.github.io/webnn/#api-neuralnetworkcontext\"\n      }}><inlineCode parentName=\"a\">{`NeuralNetworkContext`}</inlineCode></a>{` defines a set of operations that facilitate the construction and execution of this computational graph. Such operations may be accelerated with dedicated hardware such as the GPUs, CPUs with extensions for deep learning, or dedicated ML accelerators. These operations defined by the WebNN API are required by `}<a parentName=\"p\" {...{\n        \"href\": \"https://github.com/webmachinelearning/webnn/blob/master/op_compatibility/first_wave_models.md\"\n      }}>{`models`}</a>{` that address key application use cases. Additionally, the WebNN API provides affordances to builder a computational graph, compile the graph, execute the graph, and integrate the graph with other Web APIs that provide input data to the graph e.g. media APIs for image or video frames and sensor APIs for sensory data.`}</p>\n    <p>{`This `}<a parentName=\"p\" {...{\n        \"href\": \"https://webmachinelearning.github.io/webnn/#examples\"\n      }}>{`example`}</a>{` builds, compiles, and executes a graph comprised of three ops, takes four inputs and returns one output.`}</p>\n    <h2>{`Key scenarios`}</h2>\n    <p>{`There are many important `}<a parentName=\"p\" {...{\n        \"href\": \"https://webmachinelearning.github.io/webnn/#usecases-application\"\n      }}>{`application use cases`}</a>{` for high-performance neural network inference. One such use case is deep-learning noise suppression (DNS) in web-based video conferencing. The following sample shows how the `}<a parentName=\"p\" {...{\n        \"href\": \"https://github.com/microsoft/DNS-Challenge/tree/master/NSNet2-baseline\"\n      }}>{`NSNet2`}</a>{` baseline implementation of deep learning-based noise suppression model may be implemented using the WebNN API.`}</p>\n    <pre><code parentName=\"pre\" {...{\n        \"className\": \"language-JavaScript\"\n      }}>{`// Noise Suppression Net 2 (NSNet2) Baseline Model for Deep Noise Suppression Challenge (DNS) 2021.\nexport class NSNet2 {\n  constructor() {\n    this.model = null;\n    this.compiledModel = null;\n    this.frameSize = 161;\n    this.hiddenSize = 400;\n  }\n\n  async load(baseUrl, batchSize, frames) {\n    const nn = navigator.ml.getNeuralNetworkContext();\n    const builder = nn.createModelBuilder();\n    // Create constants by loading pre-trained data from .npy files.\n    const weight172 = await buildConstantByNpy(builder, baseUrl + '172.npy');\n    const biasFcIn0 = await buildConstantByNpy(builder, baseUrl + 'fc_in_0_bias.npy');\n    const weight192 = await buildConstantByNpy(builder, baseUrl + '192.npy');\n    const recurrentWeight193 = await buildConstantByNpy(builder, baseUrl + '193.npy');\n    const bias194 = await buildConstantByNpy(builder, baseUrl + '194_0.npy');\n    const recurrentBias194 = await buildConstantByNpy(builder, baseUrl + '194_1.npy');\n    const weight212 = await buildConstantByNpy(builder, baseUrl + '212.npy');\n    const recurrentWeight213 = await buildConstantByNpy(builder, baseUrl + '213.npy');\n    const bias214 = await buildConstantByNpy(builder, baseUrl + '214_0.npy');\n    const recurrentBias214 = await buildConstantByNpy(builder, baseUrl + '214_1.npy');\n    const weight215 = await buildConstantByNpy(builder, baseUrl + '215.npy');\n    const biasFcOut0 = await buildConstantByNpy(builder, baseUrl + 'fc_out_0_bias.npy');\n    const weight216 = await buildConstantByNpy(builder, baseUrl + '216.npy');\n    const biasFcOut2 = await buildConstantByNpy(builder, baseUrl + 'fc_out_2_bias.npy');\n    const weight217 = await buildConstantByNpy(builder, baseUrl + '217.npy');\n    const biasFcOut4 = await buildConstantByNpy(builder, baseUrl + 'fc_out_4_bias.npy');\n    // Build up the network.\n    const input = builder.input('input', {type: 'float32', dimensions: [batchSize, frames, this.frameSize]});\n    const relu20 = builder.relu(builder.add(builder.matmul(input, weight172), biasFcIn0));\n    const transpose31 = builder.transpose(relu20, {permutation: [1, 0, 2]});\n    const initialState92 = builder.input('initialState92', {type: 'float32', dimensions: [1, batchSize, this.hiddenSize]});\n    const [gru94, gru93] = builder.gru(transpose31, weight192, recurrentWeight193, frames, this.hiddenSize,\n        {bias: bias194, recurrentBias: recurrentBias194, initialHiddenState: initialState92, returnSequence: true});\n    const squeeze95 = builder.squeeze(gru93, {axes: [1]});\n    const initialState155 = builder.input('initialState155', {type: 'float32', dimensions: [1, batchSize, this.hiddenSize]});\n    const [gru157, gru156] = builder.gru(squeeze95, weight212, recurrentWeight213, frames, this.hiddenSize,\n        {bias: bias214, recurrentBias: recurrentBias214, initialHiddenState: initialState155, returnSequence: true});\n    const squeeze158 = builder.squeeze(gru156, {axes: [1]});\n    const transpose159 = builder.transpose(squeeze158, {permutation: [1, 0, 2]});\n    const relu163 = builder.relu(builder.add(builder.matmul(transpose159, weight215), biasFcOut0));\n    const relu167 = builder.relu(builder.add(builder.matmul(relu163, weight216), biasFcOut2));\n    const output = builder.sigmoid(builder.add(builder.matmul(relu167, weight217), biasFcOut4));\n    this.model = builder.createModel({output, gru94, gru157});\n  }\n\n  async compile(options) {\n    this.compiledModel = await this.model.compile(options);\n  }\n\n  async compute(inputBuffer, initialState92Buffer, initialState155Buffer) {\n    const inputs = {\n      input: {buffer: inputBuffer},\n      initialState92: {buffer: initialState92Buffer},\n      initialState155: {buffer: initialState155Buffer},\n    };\n    return await this.compiledModel.compute(inputs);\n  }\n}\n`}</code></pre>\n    <p>{`Try the live version of the `}<a parentName=\"p\" {...{\n        \"href\": \"https://webmachinelearning.github.io/webnn-samples/nsnet2/\"\n      }}>{`WebNN NSNet2 example`}</a>{`.  This live version builds upon `}<a parentName=\"p\" {...{\n        \"href\": \"https://github.com/webmachinelearning/webnn-samples/blob/master/nsnet2/nsnet2.js\"\n      }}>{`nsnet2.js`}</a>{` that implements the above code snippet as a JS module.`}</p>\n\n    </MDXLayout>;\n}\n\n;\nMDXContent.isMDXComponent = true;"}}